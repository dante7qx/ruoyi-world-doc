---
title: DeepSeek
date: 2025-04-09 10:05:11
permalink: /pages/2c0778/
categories:
  - AI
---

# DeepSeek教程

## 一. 概述

DeepSeek-R1 是由深度求索（DeepSeek）公司开发的高性能 AI 推理模型，专注于数学、代码和自然语言推理任务。其核心优势包括：

- 强化学习驱动：通过强化学习技术显著提升推理能力，仅需少量标注数据即可高效训练。
- 长链推理（CoT）：支持多步骤逻辑推理，能够逐步分解复杂问题并解决。
- 模型蒸馏：支持将推理能力迁移到更小型的模型中，适合资源有限的场景。
- 开源生态：遵循 MIT 开源协议，允许用户自由使用、修改和商用。

DeepSeek-R1 在多个基准测试中表现优异，性能对标 OpenAI 的 o1 正式版，同时具有更高的性价比。

|      模型      |          适用场景          | 配置要求                                                     |     成本      |
| :------------: | :------------------------: | :----------------------------------------------------------- | :-----------: |
| DeepSeek 1.5B  |   基础问答、个人开发测试   | CPU：4核（Intel i3-12100F / AMD Ryzen 5 5600G）<br>内存：8-16GB DDR4<br>显卡：纯CPU或GTX 1650（4GB显存）<br>存储：3GB+ SSD（模型文件约1.5-2GB） |  3000-5000元  |
| DeepSeek 7B/8B |  文案撰写、中等复杂度任务  | CPU：8核（AMD Ryzen 7 5700X / Intel i5-13600K）<br>内存：16-32GB DDR5<br>显卡：RTX 3060 12GB / RTX 4060（8GB显存）<br>存储：8GB+ NVMe SSD（模型文件约4-5GB） | 8000-12000元  |
|  DeepSeek 14B  | 长文本生成、企业级复杂任务 | CPU：12核（i9-13900K / Ryzen 9 7950X）<br>内存：32GB DDR5<br>显卡：RTX 4090 24GB / A5000<br>存储：15GB+ NVMe SSD（模型文件约14-28GB） |  1.5万-2万元  |
|  DeepSeek 32B  |  金融预测、高精度专业任务  | CPU：16核（Xeon Gold 6338 / EPYC 7B13）<br>内存：64GB DDR5（ECC推荐）<br>显卡：双RTX 3090 24GB / 单A100 40GB<br>存储：30GB+ NVMe SSD |   3万-4万元   |
|  DeepSeek 70B  |   科研计算、多模态预处理   | CPU：32核服务器级（Xeon Platinum 8480+）<br>内存：128GB DDR5<br>显卡：4×RTX 4090 24GB / 2×A100 80GB<br>存储：70GB+ NVMe RAID |   6万-8万元   |
| DeepSeek 671B  | 国家级AI研究、通用智能开发 | CPU：64核集群（双路EPYC 7763）<br>内存：512GB DDR4 ECC<br>显卡：8×A100/H100 80GB（总显存640GB）<br>存储：300GB+分布式存储<br>电源：2000W冗余供电 | 200万-400万元 |

## 二. 安装

环境为虚拟机 Rocky9.5，使用 [Ollama](https://ollama.com/) 来安装 `deepseek-r1`。

配置：4C8G 50G

::: tip
1.配置静态IP
```shell
## vim vim /etc/NetworkManager/system-connections/enp160.nmconnection
[ipv4]                                               
method=manual
address=172.16.125.183/24,172.16.125.2               ## 修改IP，子网掩码；网关
dns=8.8.8.8

## 重启网络服务
nmcli connection reload
nmcli connection down enp160
nmcli connection up enp160

## 测试
ping baidu.com
## 查看IP
ip a
```
2. 安装基本工具
```shell
dnf install -y tar 
dnf install python3.9-pip 
pip3 install tldr
```
3. 关闭SELINUX
```shell
grubby --update-kernel ALL --args selinux=0
## 修改 /etc/selinux/config
# SELINUX=enforcing
SELINUX=disabled
## 重启
reboot
```
:::

### 1. 下载安装[Ollama](https://ollama.com)

(1) 运行 `curl -fsSL https://ollama.com/install.sh | sh` 自动安装。

(2) 手动安装
 - 根据系统下载对应的ollama，下载地址：<a href="https://github.com/ollama/ollama/releases">https://github.com/ollama/ollama/releases</a>
 - 安装步骤，参考[官网](https://github.com/datawhalechina/handy-ollama/blob/main/docs/C2/3.%20Ollama%20%E5%9C%A8%20Linux%20%E4%B8%8B%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE.md)
```shell
cd /opt
tar xvf ollama-linux-amd64.tgz --directory=/usr/local/lib/ollama
ln -sf /usr/local/lib/ollama/bin/ollama /usr/local/bin/ollama

## 为 Ollama 创建用户和组
sudo useradd -r -s /bin/false -U -m -d /usr/share/ollama ollama
sudo usermod -a -G ollama $(whoami)

## 在该位置：/etc/systemd/system/ollama.service 创建服务文件
[Unit]
Description=Ollama Service
After=network-online.target

[Service]
ExecStart=/usr/local/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
Environment="PATH=$PATH"
Environment="OLLAMA_HOST=0.0.0.0"
Environment="OLLAMA_ORIGINS=*"

[Install]
WantedBy=default.target

## 启动服务
systemctl daemon-reload
systemctl enable ollama

## 查看日志
journalctl -e -u ollama

# 本地可通过浏览器访问，防火墙开放端口 11434。
# ss -tulnp | grep ollama 
http://172.16.125.183:11434
```

### 2. 部署deepseek-r1:1.5b

```shell
ollama run deepseek-r1:1.5b

# 看到如下信息
[root@localhost ~]# ollama run deepseek-r1:1.5b
>>> 你好
<think>

</think>

你好！很高兴见到你，有什么我可以帮忙的吗？无论是问题、建议还是闲聊，我都在这儿呢！😊

>>> /bye
[root@localhost ~]#
```

### 3. 安装[open-webui](https://docs.openwebui.com)界面化访问

1. 安装`Docker CE`

   参考`https://www.rockylinux.cn/notes/zai-rocky-linux-9-1-shang-an-zhuang-docker-ce.html`
```shell
# 添加Docker Repo
dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo
# 更新源
dnf update
# 在安装 Docker CE 的时候，会同步安装 docker-compose-plugin 插件
dnf install -y docker-ce
# 建议添加普通用户至Docker组，并以普通用户运行Docker
usermod -aG docker $USER
# 生效组用户变更配置
newgrp docker
# 启动docker
systemctl start docker
# 开机启动
systemctl enable docker
```
   
2. 下载镜像并运行

```shell
docker pull ghcr.io/open-webui/open-webui:main

## 若 Ollama 运行在同一台服务器
docker run -d -p 8100:8080 --add-host=host.docker.internal:host-gateway -v /data/open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main

## 防火墙添加端口8100
firewall-cmd --permanent --zone=public --add-port=11434/tcp
firewall-cmd --reload
```
访问：<a href="http://172.16.125.183:9100">http://172.16.125.183:8100</a>

## 三. 个人知识库

### 1. [AnythingLLM](https://anythingllm.com/)
（1）脚本安装
- 创建用户、用户组
```shell
sudo groupadd dante
sudo useradd -m -g dante
sudo passwd dante
## 将用户添加到wheel组（在Rocky Linux中，wheel组的成员可以使用sudo执行管理员命令）
sudo usermod -aG wheel dante
## 切换用户
su - dante
```
- 安装，运行 `curl -fsSL https://cdn.anythingllm.com/latest/installer.sh | sh`
- 启动，运行 `./AnythingLLMDesktop/start`

（2）docker 安装（个人推荐）
```shell
docker pull mintplexlabs/anythingllm

## 创建 volume 并赋权
mkdir /data/anythingllm
chmod -R 777 /data/anythingllm

## 运行容器
docker run -d -p 9100:3001 \
--name anythingllm \
--cap-add SYS_ADMIN \
-v /data/anythingllm:/app/server/storage \
-v /data/anythingllm/.env:/app/server/.env \
-e STORAGE_DIR="/app/server/storage" \
mintplexlabs/anythingllm:latest

## 开放端口 9100
firewall-cmd --permanent --zone=public --add-port=9100/tcp
firewall-cmd --reload
```

访问：<a href="http://172.16.125.183:9100">http://172.16.125.183:9100</a>

### 2. [Cherry Studio](https://cherry-ai.com/)

### 3. [MaxKB](https://maxkb.cn/)

## 五. 参考资料

- https://deepseek.csdn.net/67bfbe786670175f992c1a5c.html
- https://deepseek.csdn.net/67bed5ff2e30c8639006e534.html
- https://blog.csdn.net/soso678/article/details/145670623
- https://deepseek.csdn.net/67bed5ff2e30c8639006e534.html
- https://zhuanlan.zhihu.com/p/20642808493
- https://docs.openwebui.com

